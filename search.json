[
  {
    "objectID": "src/01/python_overview.html",
    "href": "src/01/python_overview.html",
    "title": "Welcome to Python!",
    "section": "",
    "text": "If you’re coming from C# or C++, this notebook will help you quickly understand Python’s syntax and key differences.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#why-python-for-aiml",
    "href": "src/01/python_overview.html#why-python-for-aiml",
    "title": "Welcome to Python!",
    "section": "Why Python for AI/ML?",
    "text": "Why Python for AI/ML?\nPython has become the dominant language in AI and machine learning because of: - Simple, readable syntax - Focus on algorithms, not syntax - Rich ecosystem - Libraries like NumPy, TensorFlow, PyTorch - Interactive development - Perfect for experimentation - Strong community - Extensive documentation and support",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#key-differences-from-cc",
    "href": "src/01/python_overview.html#key-differences-from-cc",
    "title": "Welcome to Python!",
    "section": "Key Differences from C#/C++",
    "text": "Key Differences from C#/C++\n\n1. No Semicolons or Braces\nPython uses indentation to define code blocks instead of braces {}\n\n# Python - indentation matters!\nif True:\n    print(\"This is inside the if block\")\n    print(\"Still inside the block\")\nprint(\"This is outside the block\")\n\n# Compare to C#/C++:\n# if (true) {\n#     Console.WriteLine(\"Inside block\");\n#     Console.WriteLine(\"Still inside\");\n# }\n# Console.WriteLine(\"Outside block\");\n\nThis is inside the if block\nStill inside the block\nThis is outside the block\n\n\n\n\n2. Dynamic Typing\nNo need to declare variable types - Python figures it out!\n\n# Python - dynamic typing\nname = \"Alice\"        # string\nage = 25             # integer\nheight = 5.6         # float\nis_student = True    # boolean\n\nprint(f\"Name: {name}, Age: {age}, Height: {height}, Student: {is_student}\")\n\n# Variables can change type!\nage = \"twenty-five\"  # Now it's a string\nprint(f\"Age is now: {age}\")\n\n# Compare to C#:\n# string name = \"Alice\";\n# int age = 25;\n# double height = 5.6;\n# bool isStudent = true;\n\nName: Alice, Age: 25, Height: 5.6, Student: True\nAge is now: twenty-five",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#basic-data-types-and-operations",
    "href": "src/01/python_overview.html#basic-data-types-and-operations",
    "title": "Welcome to Python!",
    "section": "Basic Data Types and Operations",
    "text": "Basic Data Types and Operations\n\n# Numbers\nx = 10\ny = 3\n\nprint(f\"Addition: {x + y}\")\nprint(f\"Division: {x / y}\")        # Always returns float\nprint(f\"Integer division: {x // y}\") # Floor division\nprint(f\"Modulo: {x % y}\")\nprint(f\"Power: {x ** y}\")\n\n# Strings\nfirst_name = \"John\"\nlast_name = \"Doe\"\nfull_name = first_name + \" \" + last_name  # Concatenation\nprint(f\"Full name: {full_name}\")\n\n# F-strings (formatted string literals) - very useful!\nmessage = f\"Hello, {full_name}! You are {age} years old.\"\nprint(message)\n\nAddition: 13\nDivision: 3.3333333333333335\nInteger division: 3\nModulo: 1\nPower: 1000\nFull name: John Doe\nHello, John Doe! You are twenty-five years old.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#collections-lists-tuples-and-dictionaries",
    "href": "src/01/python_overview.html#collections-lists-tuples-and-dictionaries",
    "title": "Welcome to Python!",
    "section": "Collections: Lists, Tuples, and Dictionaries",
    "text": "Collections: Lists, Tuples, and Dictionaries\n\nLists (like arrays, but more flexible)\n\n# Lists - mutable, ordered collections\nnumbers = [1, 2, 3, 4, 5]\nmixed_list = [\"hello\", 42, 3.14, True]  # Can hold different types!\n\nprint(f\"Numbers: {numbers}\")\nprint(f\"First number: {numbers[0]}\")\nprint(f\"Last number: {numbers[-1]}\")  # Negative indexing!\n\n# List operations\nnumbers.append(6)        # Add to end\nnumbers.insert(0, 0)     # Insert at position\nprint(f\"After modifications: {numbers}\")\n\n# List slicing\nprint(f\"First three: {numbers[:3]}\")\nprint(f\"Last three: {numbers[-3:]}\")\nprint(f\"Every other: {numbers[::2]}\")\n\nNumbers: [1, 2, 3, 4, 5]\nFirst number: 1\nLast number: 5\nAfter modifications: [0, 1, 2, 3, 4, 5, 6]\nFirst three: [0, 1, 2]\nLast three: [4, 5, 6]\nEvery other: [0, 2, 4, 6]\n\n\n\n\nDictionaries (like hash maps/dictionaries in C#)\n\n# Dictionaries - key-value pairs\nstudent = {\n    \"name\": \"Alice\",\n    \"age\": 20,\n    \"major\": \"Computer Science\",\n    \"gpa\": 3.8\n}\n\nprint(f\"Student name: {student['name']}\")\nprint(f\"Student GPA: {student['gpa']}\")\n\n# Adding/modifying entries\nstudent[\"year\"] = \"Junior\"\nstudent[\"gpa\"] = 3.9\n\nprint(f\"Updated student: {student}\")\n\n# Iterating through dictionaries\nfor key, value in student.items():\n    print(f\"{key}: {value}\")\n\nStudent name: Alice\nStudent GPA: 3.8\nUpdated student: {'name': 'Alice', 'age': 20, 'major': 'Computer Science', 'gpa': 3.9, 'year': 'Junior'}\nname: Alice\nage: 20\nmajor: Computer Science\ngpa: 3.9\nyear: Junior",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#control-flow",
    "href": "src/01/python_overview.html#control-flow",
    "title": "Welcome to Python!",
    "section": "Control Flow",
    "text": "Control Flow\n\nLoops\n\n# For loops - very different from C++/C#!\nfruits = [\"apple\", \"banana\", \"orange\"]\n\n# Iterate over items directly\nfor fruit in fruits:\n    print(f\"I like {fruit}\")\n\n# If you need indices\nfor i, fruit in enumerate(fruits):\n    print(f\"{i}: {fruit}\")\n\n# Range function for numeric loops\nfor i in range(5):  # 0 to 4\n    print(f\"Count: {i}\")\n\n# While loops work similarly to C++/C#\ncount = 0\nwhile count &lt; 3:\n    print(f\"While loop iteration: {count}\")\n    count += 1\n\nI like apple\nI like banana\nI like orange\n0: apple\n1: banana\n2: orange\nCount: 0\nCount: 1\nCount: 2\nCount: 3\nCount: 4\nWhile loop iteration: 0\nWhile loop iteration: 1\nWhile loop iteration: 2\n\n\n\n\nConditional Statements\n\nscore = 85\n\n# Note: elif instead of \"else if\"\nif score &gt;= 90:\n    grade = \"A\"\nelif score &gt;= 80:\n    grade = \"B\"\nelif score &gt;= 70:\n    grade = \"C\"\nelse:\n    grade = \"F\"\n\nprint(f\"Score: {score}, Grade: {grade}\")\n\n# Boolean operators: and, or, not (instead of &&, ||, !)\nage = 20\nhas_license = True\n\nif age &gt;= 18 and has_license:\n    print(\"Can drive!\")\nelif age &gt;= 16 or has_license:\n    print(\"Might be able to drive with restrictions\")\nelse:\n    print(\"Cannot drive\")\n\nScore: 85, Grade: B\nCan drive!",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#functions",
    "href": "src/01/python_overview.html#functions",
    "title": "Welcome to Python!",
    "section": "Functions",
    "text": "Functions\nFunctions in Python are defined with the def keyword\n\n# Basic function\ndef greet(name):\n    return f\"Hello, {name}!\"\n\n# Function with default parameters\ndef calculate_grade(score, extra_credit=0):\n    total = score + extra_credit\n    if total &gt;= 90:\n        return \"A\"\n    elif total &gt;= 80:\n        return \"B\"\n    elif total &gt;= 70:\n        return \"C\"\n    else:\n        return \"F\"\n\n# Function that returns multiple values\ndef get_name_parts(full_name):\n    parts = full_name.split()\n    first = parts[0]\n    last = parts[-1]\n    return first, last  # Returns a tuple\n\n# Using the functions\nprint(greet(\"Alice\"))\nprint(f\"Grade: {calculate_grade(85)}\")\nprint(f\"Grade with extra credit: {calculate_grade(85, 5)}\")\n\nfirst_name, last_name = get_name_parts(\"John Doe Smith\")\nprint(f\"First: {first_name}, Last: {last_name}\")\n\nHello, Alice!\nGrade: B\nGrade with extra credit: A\nFirst: John, Last: Smith",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#list-comprehensions---a-python-superpower",
    "href": "src/01/python_overview.html#list-comprehensions---a-python-superpower",
    "title": "Welcome to Python!",
    "section": "List Comprehensions - A Python Superpower!",
    "text": "List Comprehensions - A Python Superpower!\nList comprehensions provide a concise way to create lists\n\n# Traditional way (like C++/C#)\nsquares = []\nfor i in range(10):\n    squares.append(i ** 2)\nprint(f\"Squares (traditional): {squares}\")\n\n# Python way - list comprehension\nsquares = [i ** 2 for i in range(10)]\nprint(f\"Squares (comprehension): {squares}\")\n\n# With conditions\neven_squares = [i ** 2 for i in range(10) if i % 2 == 0]\nprint(f\"Even squares: {even_squares}\")\n\n# Working with strings\nwords = [\"hello\", \"world\", \"python\", \"rocks\"]\nuppercase_words = [word.upper() for word in words]\nlong_words = [word for word in words if len(word) &gt; 4]\n\nprint(f\"Uppercase: {uppercase_words}\")\nprint(f\"Long words: {long_words}\")\n\nSquares (traditional): [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nSquares (comprehension): [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nEven squares: [0, 4, 16, 36, 64]\nUppercase: ['HELLO', 'WORLD', 'PYTHON', 'ROCKS']\nLong words: ['hello', 'world', 'python', 'rocks']",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#working-with-libraries",
    "href": "src/01/python_overview.html#working-with-libraries",
    "title": "Welcome to Python!",
    "section": "Working with Libraries",
    "text": "Working with Libraries\nPython’s strength comes from its extensive library ecosystem\n\n# Import statements\nimport math\nimport random\nfrom datetime import datetime\n\n# Using math library\nprint(f\"Pi: {math.pi}\")\nprint(f\"Square root of 16: {math.sqrt(16)}\")\nprint(f\"Sine of 90 degrees: {math.sin(math.radians(90))}\")\n\n# Random numbers\nprint(f\"Random number: {random.randint(1, 100)}\")\nprint(f\"Random choice: {random.choice(['red', 'blue', 'green'])}\")\n\n# Date and time\nnow = datetime.now()\nprint(f\"Current time: {now}\")\nprint(f\"Formatted: {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n\nPi: 3.141592653589793\nSquare root of 16: 4.0\nSine of 90 degrees: 1.0\nRandom number: 78\nRandom choice: green\nCurrent time: 2025-05-30 13:23:00.817462\nFormatted: 2025-05-30 13:23:00",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#exception-handling",
    "href": "src/01/python_overview.html#exception-handling",
    "title": "Welcome to Python!",
    "section": "Exception Handling",
    "text": "Exception Handling\nSimilar to C#, but with try/except instead of try/catch\n\ndef safe_divide(a, b):\n    try:\n        result = a / b\n        return result\n    except ZeroDivisionError:\n        print(\"Error: Cannot divide by zero!\")\n        return None\n    except TypeError:\n        print(\"Error: Invalid types for division!\")\n        return None\n    finally:\n        print(\"Division operation completed\")\n\n# Test the function\nprint(f\"10 / 2 = {safe_divide(10, 2)}\")\nprint(f\"10 / 0 = {safe_divide(10, 0)}\")\nprint(f\"'10' / 'hello' = {safe_divide('10', 'hello')}\")\n\nDivision operation completed\n10 / 2 = 5.0\nError: Cannot divide by zero!\nDivision operation completed\n10 / 0 = None\nError: Invalid types for division!\nDivision operation completed\n'10' / 'hello' = None",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#classes-and-objects",
    "href": "src/01/python_overview.html#classes-and-objects",
    "title": "Welcome to Python!",
    "section": "Classes and Objects",
    "text": "Classes and Objects\nObject-oriented programming in Python\n\nclass Student:\n    # Class variable (shared by all instances)\n    school_name = \"University of AI\"\n    \n    def __init__(self, name, age, major):  # Constructor\n        self.name = name      # Instance variables\n        self.age = age\n        self.major = major\n        self.grades = []\n    \n    def add_grade(self, grade):\n        self.grades.append(grade)\n    \n    def get_gpa(self):\n        if not self.grades:\n            return 0.0\n        return sum(self.grades) / len(self.grades)\n    \n    def __str__(self):  # String representation\n        return f\"{self.name}, {self.age} years old, majoring in {self.major}\"\n\n# Create and use objects\nalice = Student(\"Alice\", 20, \"Computer Science\")\nbob = Student(\"Bob\", 19, \"Mathematics\")\n\nalice.add_grade(3.8)\nalice.add_grade(3.9)\nalice.add_grade(4.0)\n\nprint(alice)\nprint(f\"Alice's GPA: {alice.get_gpa():.2f}\")\nprint(f\"School: {Student.school_name}\")\n\nAlice, 20 years old, majoring in Computer Science\nAlice's GPA: 3.90\nSchool: University of AI",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#file-io",
    "href": "src/01/python_overview.html#file-io",
    "title": "Welcome to Python!",
    "section": "File I/O",
    "text": "File I/O\nReading and writing files in Python\n\n# Writing to a file\nstudents_data = [\n    \"Alice,20,Computer Science,3.8\",\n    \"Bob,19,Mathematics,3.6\",\n    \"Charlie,21,Physics,3.9\"\n]\n\n# Write data to file\nwith open(\"students.txt\", \"w\") as file:\n    for line in students_data:\n        file.write(line + \"\\n\")\n\nprint(\"Data written to students.txt\")\n\n# Reading from a file\nprint(\"\\nReading data back:\")\nwith open(\"students.txt\", \"r\") as file:\n    for line in file:\n        name, age, major, gpa = line.strip().split(\",\")\n        print(f\"Name: {name}, Age: {age}, Major: {major}, GPA: {gpa}\")\n\n# The 'with' statement automatically closes the file\n# This is similar to 'using' in C#\n\nData written to students.txt\n\nReading data back:\nName: Alice, Age: 20, Major: Computer Science, GPA: 3.8\nName: Bob, Age: 19, Major: Mathematics, GPA: 3.6\nName: Charlie, Age: 21, Major: Physics, GPA: 3.9",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#common-python-idioms",
    "href": "src/01/python_overview.html#common-python-idioms",
    "title": "Welcome to Python!",
    "section": "Common Python Idioms",
    "text": "Common Python Idioms\nThese patterns are very “Pythonic” and you’ll see them everywhere\n\n# 1. Checking if a list is empty\nmy_list = []\nif not my_list:  # Pythonic way\n    print(\"List is empty\")\n\n# 2. Swapping variables\na, b = 10, 20\nprint(f\"Before swap: a={a}, b={b}\")\na, b = b, a  # Pythonic swap!\nprint(f\"After swap: a={a}, b={b}\")\n\n# 3. Multiple assignment\nname, age, major = \"Alice\", 20, \"CS\"\nprint(f\"Name: {name}, Age: {age}, Major: {major}\")\n\n# 4. Enumerate for index and value\nfruits = [\"apple\", \"banana\", \"orange\"]\nfor i, fruit in enumerate(fruits):\n    print(f\"{i}: {fruit}\")\n\n# 5. Zip for parallel iteration\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nscores = [95, 87, 92]\nfor name, score in zip(names, scores):\n    print(f\"{name}: {score}\")\n\n# 6. String methods\ntext = \"  Hello, World!  \"\nprint(f\"Original: '{text}'\")\nprint(f\"Stripped: '{text.strip()}'\")\nprint(f\"Lower: '{text.lower()}'\")\nprint(f\"Replace: '{text.replace('World', 'Python')}'\")\n\nList is empty\nBefore swap: a=10, b=20\nAfter swap: a=20, b=10\nName: Alice, Age: 20, Major: CS\n0: apple\n1: banana\n2: orange\nAlice: 95\nBob: 87\nCharlie: 92\nOriginal: '  Hello, World!  '\nStripped: 'Hello, World!'\nLower: '  hello, world!  '\nReplace: '  Hello, Python!  '",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#quick-reference-python-vs-cc",
    "href": "src/01/python_overview.html#quick-reference-python-vs-cc",
    "title": "Welcome to Python!",
    "section": "Quick Reference: Python vs C#/C++",
    "text": "Quick Reference: Python vs C#/C++\n\n\n\nFeature\nC#/C++\nPython\n\n\n\n\nVariable declaration\nint x = 5;\nx = 5\n\n\nString formatting\n$\"Hello {name}\"\nf\"Hello {name}\"\n\n\nArrays/Lists\nint[] arr = {1,2,3};\narr = [1, 2, 3]\n\n\nFor loop\nfor(int i=0; i&lt;10; i++)\nfor i in range(10):\n\n\nConditional\nif (condition) { }\nif condition:\n\n\nFunction\npublic int Add(int a, int b)\ndef add(a, b):\n\n\nComments\n// comment or /* */\n# comment\n\n\nBoolean operators\n&&, \\|\\|, !\nand, or, not\n\n\nNull/None\nnull\nNone",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/python_overview.html#next-steps",
    "href": "src/01/python_overview.html#next-steps",
    "title": "Welcome to Python!",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you understand Python basics:\n\nPractice - Try converting some of your C#/C++ programs to Python\nExplore libraries - NumPy for numerical computing, Pandas for data analysis\nLearn AI/ML libraries - TensorFlow, PyTorch, scikit-learn\nEmbrace Python idioms - Write “Pythonic” code\n\nRemember: Python prioritizes readability and simplicity. When in doubt, choose the more readable option!",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Welcome to Python!"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html",
    "href": "src/01/intro_notebooks.html",
    "title": "Introduction to Jupyter Notebooks",
    "section": "",
    "text": "Welcome to your first Jupyter notebook! This interactive document will teach you the fundamentals of working with notebooks.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#what-is-a-jupyter-notebook",
    "href": "src/01/intro_notebooks.html#what-is-a-jupyter-notebook",
    "title": "Introduction to Jupyter Notebooks",
    "section": "What is a Jupyter Notebook?",
    "text": "What is a Jupyter Notebook?\nA Jupyter notebook is an interactive computing environment that allows you to: - Write and execute code in cells - Include rich text, equations, and visualizations - Document your thought process alongside your code - Share reproducible research and analysis\nNotebooks are widely used in data science, machine learning, research, and education.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#cell-types",
    "href": "src/01/intro_notebooks.html#cell-types",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Cell Types",
    "text": "Cell Types\nNotebooks consist of cells - the building blocks of your document. There are two main types:\n\nMarkdown cells (like this one) - for text, documentation, and formatting\nCode cells - for executable code\n\n\n# This is a code cell!\n# Let's start with a simple Python example\n\nprint(\"Hello, Jupyter!\")\nprint(\"This code will execute when you run the cell\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#running-cells",
    "href": "src/01/intro_notebooks.html#running-cells",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Running Cells",
    "text": "Running Cells\nTo execute a cell, you have several options: - Shift + Enter - Run cell and move to next - Ctrl + Enter - Run cell and stay in current cell - Click the “Run” button in the toolbar\nTry running the code cell above!\n\n# Variables persist between cells\nname = \"CS Student\"\ncourse = \"Applied GenAI\"\n\nprint(f\"Welcome {name} to {course}!\")\n\n\n# The variable 'name' from the previous cell is still available\nprint(f\"Your name is: {name}\")\n\n# Let's do some basic math\nx = 10\ny = 5\nresult = x * y\n\nprint(f\"{x} × {y} = {result}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#working-with-libraries",
    "href": "src/01/intro_notebooks.html#working-with-libraries",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Working with Libraries",
    "text": "Working with Libraries\nNotebooks are perfect for data analysis and visualization. Let’s import some common libraries:\n\n# Import common libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create some sample data\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\n# Create a simple plot\nplt.figure(figsize=(8, 4))\nplt.plot(x, y, 'b-', linewidth=2)\nplt.title('Sine Wave')\nplt.xlabel('x')\nplt.ylabel('sin(x)')\nplt.grid(True, alpha=0.3)\nplt.show()",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#markdown-features",
    "href": "src/01/intro_notebooks.html#markdown-features",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Markdown Features",
    "text": "Markdown Features\nMarkdown cells support rich formatting:\n\nText Formatting\n\nBold text\nItalic text\nCode snippets\n\n\n\nLists\n\nNumbered lists\nAre great for\nStep-by-step instructions\n\n\n\nMath Equations\nYou can include LaTeX math: \\(E = mc^2\\)\nOr display equations: \\[\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}\\]\n\n# Let's explore some data structures\nstudents = ['Alice', 'Bob', 'Charlie', 'Diana']\ngrades = [92, 87, 95, 89]\n\n# Create a simple grade report\nprint(\"Grade Report:\")\nprint(\"-\" * 20)\nfor student, grade in zip(students, grades):\n    print(f\"{student}: {grade}%\")\n\n# Calculate average\naverage = sum(grades) / len(grades)\nprint(f\"\\nClass Average: {average:.1f}%\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#key-benefits-of-notebooks",
    "href": "src/01/intro_notebooks.html#key-benefits-of-notebooks",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Key Benefits of Notebooks",
    "text": "Key Benefits of Notebooks\n\nInteractive Development - Test code incrementally\nDocumentation - Combine code with explanations\nVisualization - Plots and charts display inline\nReproducibility - Share complete analysis workflows\nEducation - Perfect for learning and teaching",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/intro_notebooks.html#next-steps",
    "href": "src/01/intro_notebooks.html#next-steps",
    "title": "Introduction to Jupyter Notebooks",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you understand the basics: - Experiment with creating your own cells - Try different types of code and markdown - Explore the toolbar and menu options - Practice the keyboard shortcuts\nRemember: Notebooks are meant to be interactive - don’t just read, experiment!",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Python and Jupyter",
      "Introduction to Jupyter Notebooks"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#openais-text-embeddings",
    "href": "src/01/embeddings_using_openai.html#openais-text-embeddings",
    "title": "Exploring Embeddings using OpenAI",
    "section": "OpenAI’s Text Embeddings",
    "text": "OpenAI’s Text Embeddings\nOpenAI provides state-of-the-art text embedding models that convert text into high-dimensional vectors. These embeddings capture semantic meaning and can be used for various tasks like:\n\nSemantic search: Finding similar documents or passages\nClustering: Grouping similar texts together\nClassification: Using embeddings as features for ML models\nRecommendation systems: Finding similar content\n\nIn this notebook, we’ll explore OpenAI’s text-embedding-ada-002 model, which produces 1536-dimensional vectors and is optimized for both quality and cost.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#setup-and-api-key",
    "href": "src/01/embeddings_using_openai.html#setup-and-api-key",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Setup and API Key",
    "text": "Setup and API Key\nBefore running this notebook, make sure you have: 1. An OpenAI API key (set as environment variable OPENAI_API_KEY) 2. The OpenAI Python library installed: pip install openai\nNote: Using OpenAI’s API incurs costs. The embedding model is relatively inexpensive, but be mindful of your usage.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#generate-your-first-embedding",
    "href": "src/01/embeddings_using_openai.html#generate-your-first-embedding",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Generate Your First Embedding",
    "text": "Generate Your First Embedding\nLet’s start by generating an embedding for a simple text string. The embedding will be a list of 1536 floating-point numbers that represent the semantic meaning of the text.\n\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.embeddings.create(\n    input=\"Your text string goes here\",\n    model=\"text-embedding-ada-002\"\n)\n\nprint(f\"Embedding dimensions: {len(response.data[0].embedding)}\")\nprint(f\"First 10 values: {response.data[0].embedding[:10]}\")\nprint(f\"Full embedding: {response.data[0].embedding}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#understanding-the-output",
    "href": "src/01/embeddings_using_openai.html#understanding-the-output",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Understanding the Output",
    "text": "Understanding the Output\nTry this: Change the input text in the cell above and run it again. Notice how: - The embedding always has 1536 dimensions - Different texts produce different embeddings - The values are typically between -1 and 1\nQuestion to consider: What happens when you use the exact same text twice? Do you get identical embeddings?",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#comparing-embeddings-semantic-similarity",
    "href": "src/01/embeddings_using_openai.html#comparing-embeddings-semantic-similarity",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Comparing Embeddings: Semantic Similarity",
    "text": "Comparing Embeddings: Semantic Similarity\nThe real power of embeddings comes from comparing them. We can measure how similar two pieces of text are by calculating the cosine similarity between their embeddings.\nCosine similarity ranges from -1 to 1: - 1 = identical meaning - 0 = no relationship - -1 = opposite meaning\n\nfrom scipy.spatial.distance import cosine\n\n# Generate embeddings for two similar sentences\nresponse = client.embeddings.create(\n    input=[\"The cat sat on the mat.\",\n           \"A feline rested on a rug.\"],\n    model=\"text-embedding-ada-002\"\n)\n\nembedding_a = response.data[0].embedding\nembedding_b = response.data[1].embedding\n\n# Calculate cosine similarity (1 - cosine distance)\nsimilarity_score = 1 - cosine(embedding_a, embedding_b)\nprint(f\"Cosine similarity: {similarity_score:.4f}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#experiment-with-different-text-pairs",
    "href": "src/01/embeddings_using_openai.html#experiment-with-different-text-pairs",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Experiment with Different Text Pairs",
    "text": "Experiment with Different Text Pairs\nTry these experiments by modifying the input texts in the cell above:\n\nSynonymous sentences:\n\n“The dog is running” vs “The canine is jogging”\n\nRelated but different topics:\n\n“I love pizza” vs “Italian food is delicious”\n\nCompletely unrelated:\n\n“The weather is sunny” vs “Mathematics is challenging”\n\nOpposite meanings:\n\n“I am happy” vs “I am sad”\n\n\nQuestions to explore: - What similarity scores do you get for each pair? - Do the scores align with your intuition about semantic similarity? - How does this compare to simple word matching?",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#batch-processing-multiple-texts",
    "href": "src/01/embeddings_using_openai.html#batch-processing-multiple-texts",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Batch Processing Multiple Texts",
    "text": "Batch Processing Multiple Texts\nFor efficiency, you can generate embeddings for multiple texts in a single API call. This is more cost-effective and faster than individual calls.\n\n# Multiple texts to embed\ntexts = [\n    \"The cat sat on the mat.\",\n    \"A feline rested on a rug.\",\n    \"Dogs are loyal companions.\",\n    \"The weather is beautiful today.\",\n    \"Machine learning is fascinating.\"\n]\n\n# Generate embeddings for all texts\nresponse = client.embeddings.create(\n    input=texts,\n    model=\"text-embedding-ada-002\"\n)\n\n# Extract embeddings\nembeddings = [data.embedding for data in response.data]\n\nprint(f\"Generated {len(embeddings)} embeddings\")\nprint(f\"Each embedding has {len(embeddings[0])} dimensions\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#creating-a-similarity-matrix",
    "href": "src/01/embeddings_using_openai.html#creating-a-similarity-matrix",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Creating a Similarity Matrix",
    "text": "Creating a Similarity Matrix\nLet’s create a matrix showing the similarity between all pairs of texts. This helps visualize which texts are most similar to each other.\n\nimport numpy as np\nimport pandas as pd\n\n# Calculate similarity matrix\nn_texts = len(embeddings)\nsimilarity_matrix = np.zeros((n_texts, n_texts))\n\nfor i in range(n_texts):\n    for j in range(n_texts):\n        if i == j:\n            similarity_matrix[i][j] = 1.0  # Perfect similarity with itself\n        else:\n            similarity_matrix[i][j] = 1 - cosine(embeddings[i], embeddings[j])\n\n# Create a DataFrame for better visualization\nsimilarity_df = pd.DataFrame(\n    similarity_matrix, \n    index=[f\"Text {i+1}\" for i in range(n_texts)],\n    columns=[f\"Text {i+1}\" for i in range(n_texts)]\n)\n\nprint(\"Similarity Matrix:\")\nprint(similarity_df.round(3))\n\nprint(\"\\nOriginal texts:\")\nfor i, text in enumerate(texts):\n    print(f\"Text {i+1}: {text}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#analysis-questions",
    "href": "src/01/embeddings_using_openai.html#analysis-questions",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Analysis Questions",
    "text": "Analysis Questions\nLooking at the similarity matrix above:\n\nWhich two texts are most similar? Why do you think this is?\nWhich texts are least similar? Does this make sense semantically?\nHow do the similarity scores compare to what you would expect intuitively?\n\nAdvanced exploration: Try adding more texts to the list and see how the similarity patterns change. Consider texts from different domains (sports, technology, cooking, etc.).",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_openai.html#key-takeaways",
    "href": "src/01/embeddings_using_openai.html#key-takeaways",
    "title": "Exploring Embeddings using OpenAI",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nFrom this exploration, you should understand:\n\nEmbeddings are dense vector representations of text that capture semantic meaning\nOpenAI’s embeddings are high-quality and can detect semantic similarity even when words are different\nCosine similarity is a standard way to measure how similar two embeddings are\nBatch processing is more efficient for multiple texts\nEmbeddings enable many AI applications like search, recommendation, and classification\n\nNext steps: Try using these embeddings in a real application, such as building a semantic search system or a text classifier!",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using OpenAI"
    ]
  },
  {
    "objectID": "src/01/recap.html#slide-1",
    "href": "src/01/recap.html#slide-1",
    "title": "Neural Network Architectures - A recap",
    "section": "Slide 1",
    "text": "Slide 1\n\nBullet 1\nBullet 2",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Slides"
    ]
  },
  {
    "objectID": "src/01/recap.html#slide-2",
    "href": "src/01/recap.html#slide-2",
    "title": "Neural Network Architectures - A recap",
    "section": "Slide 2",
    "text": "Slide 2\n\nBullet 1\nBullet 2",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Slides"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Generative AI Course (DigiPen)",
    "section": "",
    "text": "“Applied Generative AI” is a comprehensive 15-week course designed for computer science majors (BSCS, BSCSML, BSCSGD), focusing on the fundamentals and practical applications of generative AI within the gaming industry.\nStudents will explore neural network architectures, including the impact of the Transformer model, delve into large language models beyond ChatGPT, and experiment with multimodal models for image and audio generation. The course offers hands-on experience with both hosted and locally run models, integration with game engines like Unity and Unreal, and the development of AI-driven game characters and environments.\nEthical considerations and model evaluation are woven throughout the curriculum, ensuring students not only master technical skills but also understand the broader societal implications of their work. Through lectures, lab sessions, and a final project, students will gain the expertise to leverage generative AI in creating innovative, interactive gaming experiences.",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Applied Generative AI Course (DigiPen)",
    "section": "",
    "text": "“Applied Generative AI” is a comprehensive 15-week course designed for computer science majors (BSCS, BSCSML, BSCSGD), focusing on the fundamentals and practical applications of generative AI within the gaming industry.\nStudents will explore neural network architectures, including the impact of the Transformer model, delve into large language models beyond ChatGPT, and experiment with multimodal models for image and audio generation. The course offers hands-on experience with both hosted and locally run models, integration with game engines like Unity and Unreal, and the development of AI-driven game characters and environments.\nEthical considerations and model evaluation are woven throughout the curriculum, ensuring students not only master technical skills but also understand the broader societal implications of their work. Through lectures, lab sessions, and a final project, students will gain the expertise to leverage generative AI in creating innovative, interactive gaming experiences.",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "src/00/teaching_lecture.html#recap-of-last-lecture",
    "href": "src/00/teaching_lecture.html#recap-of-last-lecture",
    "title": "Introducing AI Agents",
    "section": "Recap of Last Lecture",
    "text": "Recap of Last Lecture\nWe used the OpenAI SDK to build our first AI-powered chatbot!\n\n\nScreenshot of the chatbot interface"
  },
  {
    "objectID": "src/00/teaching_lecture.html#what-did-we-learn",
    "href": "src/00/teaching_lecture.html#what-did-we-learn",
    "title": "Introducing AI Agents",
    "section": "What Did We Learn?",
    "text": "What Did We Learn?\n\nHow to use OpenAI API and SDK\nContext windows and conversation structure\nAvailable models, features, and costs"
  },
  {
    "objectID": "src/00/teaching_lecture.html#but-we-discovered-limitations",
    "href": "src/00/teaching_lecture.html#but-we-discovered-limitations",
    "title": "Introducing AI Agents",
    "section": "But We Discovered Limitations",
    "text": "But We Discovered Limitations\nOur simple chatbot had several constraints…\n\nNot Proactive: No ability to plan beyond a single interaction\nNo Autonomy: Needs constant human input every turn\nNot Reactive: Cannot respond to different conditions\nNo Memory: Everything has to be replayed in the context window\nNo Interactivity: Cannot reach out to other LLMs and external systems"
  },
  {
    "objectID": "src/00/teaching_lecture.html#the-need-for-ai-agents",
    "href": "src/00/teaching_lecture.html#the-need-for-ai-agents",
    "title": "Introducing AI Agents",
    "section": "The Need for AI Agents",
    "text": "The Need for AI Agents\nThese limitations point to a fundamental gap in our current approach…"
  },
  {
    "objectID": "src/10/rubric.html",
    "href": "src/10/rubric.html",
    "title": "Final Project: AI-Enhanced Game Environment",
    "section": "",
    "text": "Students will design and implement a game environment that integrates generative AI to create dynamic, engaging player experiences. The project should demonstrate the use of at least two different generative AI techniques covered in the course, such as LLMs for dialogue, procedural generation for levels or assets, or multimodal AI for interactive audio-visual elements. The final deliverable should include a playable game prototype, a technical presentation detailing the integration and optimization of AI models, and an ethical evaluation of the AI’s impact on gameplay.\n\n\n\nTechnical Implementation (40%)\n\nIntegration of AI Models (20%): Effective integration of at least two generative AI techniques. Models should be appropriately chosen and optimized for their respective tasks.\nFunctionality (20%): The game should be fully playable with AI components functioning as intended, enhancing gameplay and interactions.\n\nInnovation and Creativity (20%)\n\nOriginality (10%): Creative use of AI to provide unique and compelling gameplay experiences.\nDesign (10%): Aesthetic and functional design that leverages AI to enhance the game’s visual and interactive elements.\n\nPresentation (20%)\n\nPresentation (20%): Clear and engaging presentation of the game, highlighting AI features and their impact on player experience. Comprehensive explanation of the AI integration process, including model selection, challenges faced, and solutions implemented.\n\nEthical Considerations (10%)\n\nEthical Analysis (10%): Evaluation of potential biases, ethical implications, and societal impacts of the AI components used in the game. Proposals for mitigating identified risks.\n\nCollaboration and Effort (10%)\n\nTeamwork (10%): Effective collaboration among team members, with roles and contributions clearly defined. Measured by peer feedback.\n\n\nTeams will be 2-4 students, depending on class size. The final presentations will be held on the last class of the semester. We will also bring in 2-3 industry guest judges to provide feedback on projects.",
    "crumbs": [
      "Module 10: Final Project",
      "Final Project: AI-Enhanced Game Environment"
    ]
  },
  {
    "objectID": "src/10/rubric.html#rubric",
    "href": "src/10/rubric.html#rubric",
    "title": "Final Project: AI-Enhanced Game Environment",
    "section": "",
    "text": "Technical Implementation (40%)\n\nIntegration of AI Models (20%): Effective integration of at least two generative AI techniques. Models should be appropriately chosen and optimized for their respective tasks.\nFunctionality (20%): The game should be fully playable with AI components functioning as intended, enhancing gameplay and interactions.\n\nInnovation and Creativity (20%)\n\nOriginality (10%): Creative use of AI to provide unique and compelling gameplay experiences.\nDesign (10%): Aesthetic and functional design that leverages AI to enhance the game’s visual and interactive elements.\n\nPresentation (20%)\n\nPresentation (20%): Clear and engaging presentation of the game, highlighting AI features and their impact on player experience. Comprehensive explanation of the AI integration process, including model selection, challenges faced, and solutions implemented.\n\nEthical Considerations (10%)\n\nEthical Analysis (10%): Evaluation of potential biases, ethical implications, and societal impacts of the AI components used in the game. Proposals for mitigating identified risks.\n\nCollaboration and Effort (10%)\n\nTeamwork (10%): Effective collaboration among team members, with roles and contributions clearly defined. Measured by peer feedback.\n\n\nTeams will be 2-4 students, depending on class size. The final presentations will be held on the last class of the semester. We will also bring in 2-3 industry guest judges to provide feedback on projects.",
    "crumbs": [
      "Module 10: Final Project",
      "Final Project: AI-Enhanced Game Environment"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#what-are-vector-embeddings",
    "href": "src/01/embeddings_using_spacy.html#what-are-vector-embeddings",
    "title": "Exploring Embeddings using spaCy",
    "section": "What are Vector Embeddings?",
    "text": "What are Vector Embeddings?\nVector embeddings are numerical representations that map complex data—such as words, sentences, or images—into a continuous, high-dimensional vector space. This transformation enables machines to capture and process semantic relationships and contextual meanings inherent in the data. For instance, in natural language processing (NLP), word embeddings position semantically similar words closer together in the vector space, facilitating tasks like sentiment analysis, machine translation, and information retrieval.\nIn this notebook, we’ll use spaCy, a popular Python library for NLP that includes pre-trained word embeddings. spaCy’s embeddings are based on word2vec and are trained on large text corpora to capture semantic relationships between words.",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#spacy-dependencies",
    "href": "src/01/embeddings_using_spacy.html#spacy-dependencies",
    "title": "Exploring Embeddings using spaCy",
    "section": "spaCy Dependencies",
    "text": "spaCy Dependencies\nRun the following cell to download the English pipeline (medium) optimized for CPU. This model includes: - Word vectors: 300-dimensional embeddings for ~685k words - Part-of-speech tagging: Grammatical information - Named entity recognition: Identifying people, places, organizations, etc. - Dependency parsing: Understanding sentence structure\nYou can find more information here: https://spacy.io/models/en#en_core_web_md\n\n!python -m spacy download en_core_web_md",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#generate-embeddings",
    "href": "src/01/embeddings_using_spacy.html#generate-embeddings",
    "title": "Exploring Embeddings using spaCy",
    "section": "Generate Embeddings",
    "text": "Generate Embeddings\nLet’s start by generating embeddings for a simple sentence. spaCy automatically creates document-level embeddings by averaging the word vectors in the text.\nTry this: Run the code below, then try with other words, sentences, or paragraphs. What do you notice about the embedding dimensions and values?\n\nimport spacy\n\n# Load the pre-trained model\nnlp = spacy.load(\"en_core_web_md\")\n\n# Process the word/sentence\ndoc = nlp(\"The cat sat on the mat.\")\n\n# Display information about the embeddings\nprint(f\"Text: '{doc.text}'\")\nprint(f\"Embedding dimensions: {len(doc.vector)}\")\nprint(f\"First 10 values: {doc.vector[:10]}\")\nprint(f\"\\nFull embedding: {doc.vector}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#understanding-word-vs-document-embeddings",
    "href": "src/01/embeddings_using_spacy.html#understanding-word-vs-document-embeddings",
    "title": "Exploring Embeddings using spaCy",
    "section": "Understanding Word vs Document Embeddings",
    "text": "Understanding Word vs Document Embeddings\nspaCy provides embeddings at different levels: - Token (word) level: Each individual word has its own embedding - Document level: The entire text gets a single embedding (average of word embeddings)\nLet’s explore both:\n\n# Process a sentence\ndoc = nlp(\"The cat sat on the mat.\")\n\nprint(\"Word-level embeddings:\")\nfor token in doc:\n    if token.has_vector:  # Check if the word has an embedding\n        print(f\"'{token.text}': {len(token.vector)} dimensions, first 5 values: {token.vector[:5]}\")\n    else:\n        print(f\"'{token.text}': No embedding available\")\n\nprint(f\"\\nDocument-level embedding: {len(doc.vector)} dimensions\")\nprint(f\"Document vector (first 10): {doc.vector[:10]}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#investigate-similarity",
    "href": "src/01/embeddings_using_spacy.html#investigate-similarity",
    "title": "Exploring Embeddings using spaCy",
    "section": "Investigate Similarity",
    "text": "Investigate Similarity\nWe can use spaCy’s built-in similarity function to generate a similarity score between two pieces of text. This function calculates the cosine similarity between the embeddings.\nSimilarity scores range from 0 to 1: - 1 = identical meaning - 0 = no relationship\n\nimport spacy\n\n# Load the pre-trained model\nnlp = spacy.load(\"en_core_web_md\")\n\n# Process the sentences\ndoc1 = nlp(\"The cat sat on the mat.\")\ndoc2 = nlp(\"A feline rested on a rug.\")\n\n# Compute similarity\nsimilarity_score = doc1.similarity(doc2)\n\nprint(f\"Text 1: '{doc1.text}'\")\nprint(f\"Text 2: '{doc2.text}'\")\nprint(f\"Similarity score: {similarity_score:.4f}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#syntactic-vs-semantic-similarity",
    "href": "src/01/embeddings_using_spacy.html#syntactic-vs-semantic-similarity",
    "title": "Exploring Embeddings using spaCy",
    "section": "Syntactic vs Semantic Similarity",
    "text": "Syntactic vs Semantic Similarity\nWhat do you notice about the similarity scores? Are they capturing syntactic (word structure) or semantic (meaning) similarity?\nExperiment: Re-run the previous cell with different sentence pairs to find out. Try these examples:\n\nSame words, different order:\n\n“The dog chased the cat” vs “The cat chased the dog”\n\nSynonyms:\n\n“The car is fast” vs “The automobile is quick”\n\nDifferent topics:\n\n“I love programming” vs “The weather is nice”\n\n\nQuestions to consider: - Do sentences with similar meanings but different words get high similarity scores? - Do sentences with the same words but different meanings get high scores? - What does this tell you about what the embeddings are capturing?",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#comparing-multiple-texts",
    "href": "src/01/embeddings_using_spacy.html#comparing-multiple-texts",
    "title": "Exploring Embeddings using spaCy",
    "section": "Comparing Multiple Texts",
    "text": "Comparing Multiple Texts\nLet’s create a more comprehensive comparison by looking at multiple texts and their pairwise similarities:\n\n# Define multiple texts to compare\ntexts = [\n    \"The cat sat on the mat.\",\n    \"A feline rested on a rug.\",\n    \"Dogs are loyal pets.\",\n    \"The weather is sunny today.\",\n    \"Programming is fun and challenging.\"\n]\n\n# Process all texts\ndocs = [nlp(text) for text in texts]\n\n# Create similarity matrix\nprint(\"Pairwise Similarity Scores:\")\nprint(\"=\" * 50)\n\nfor i, doc1 in enumerate(docs):\n    for j, doc2 in enumerate(docs):\n        if i &lt; j:  # Only show upper triangle to avoid duplicates\n            similarity = doc1.similarity(doc2)\n            print(f\"Text {i+1} vs Text {j+1}: {similarity:.4f}\")\n            print(f\"  '{doc1.text}' vs '{doc2.text}'\")\n            print()\n\nprint(\"\\nText Reference:\")\nfor i, text in enumerate(texts):\n    print(f\"Text {i+1}: {text}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#word-level-similarity-analysis",
    "href": "src/01/embeddings_using_spacy.html#word-level-similarity-analysis",
    "title": "Exploring Embeddings using spaCy",
    "section": "Word-Level Similarity Analysis",
    "text": "Word-Level Similarity Analysis\nLet’s also explore similarity at the word level to understand how individual words relate to each other:\n\n# Compare individual words\nwords = [\"cat\", \"feline\", \"dog\", \"canine\", \"car\", \"automobile\", \"happy\", \"joyful\", \"sad\"]\n\n# Process words\nword_docs = [nlp(word) for word in words]\n\nprint(\"Word Similarity Examples:\")\nprint(\"=\" * 30)\n\n# Compare some interesting word pairs\npairs = [\n    (\"cat\", \"feline\"),\n    (\"dog\", \"canine\"), \n    (\"car\", \"automobile\"),\n    (\"happy\", \"joyful\"),\n    (\"happy\", \"sad\"),\n    (\"cat\", \"dog\"),\n    (\"cat\", \"car\")\n]\n\nfor word1, word2 in pairs:\n    doc1 = nlp(word1)\n    doc2 = nlp(word2)\n    similarity = doc1.similarity(doc2)\n    print(f\"'{word1}' vs '{word2}': {similarity:.4f}\")",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/embeddings_using_spacy.html#key-takeaways",
    "href": "src/01/embeddings_using_spacy.html#key-takeaways",
    "title": "Exploring Embeddings using spaCy",
    "section": "Key Takeaways",
    "text": "Key Takeaways\nFrom this exploration with spaCy embeddings, you should understand:\n\nspaCy provides 300-dimensional word embeddings trained on large text corpora\nDocument embeddings are averages of the individual word embeddings\nSimilarity scores capture semantic relationships between words and texts\nEmbeddings work at multiple levels - individual words, sentences, and documents\nPre-trained models like spaCy’s make it easy to get started with embeddings\n\nComparison with other approaches: - spaCy embeddings are based on older techniques (word2vec) but are fast and work well for many tasks - Modern transformer-based models (like OpenAI’s embeddings) often provide better semantic understanding - The choice depends on your specific use case, computational resources, and accuracy requirements\nNext steps: Try experimenting with different types of text (technical documents, creative writing, news articles) to see how well the embeddings capture domain-specific relationships!",
    "crumbs": [
      "Module 1: Foundations of Generative AI",
      "Vector Embeddings",
      "Exploring Embeddings using spaCy"
    ]
  },
  {
    "objectID": "src/01/nanogpt.html",
    "href": "src/01/nanogpt.html",
    "title": "Placeholder for NanoGPT workbook",
    "section": "",
    "text": "print(\"Hello 123\")\n\nHello 123"
  }
]